{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731ff4a2",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup MetaForge Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733054a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MetaForge from PyPI (latest stable)\n",
    "!pip install metaforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05142ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For development/testing from source:\n",
    "# !pip install git+https://github.com/Mageed-Ghaleb/MetaForge.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aefe13",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae036fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaforge.problems.benchmark_loader import load_job_shop_instance\n",
    "from metaforge.utils.compare_solvers import compare_solvers, compare_all_benchmarks\n",
    "from metaforge.utils.plotting import (\n",
    "    plot_solver_comparison,\n",
    "    plot_solver_dashboard,\n",
    "    plot_convergence_comparison,\n",
    "    plot_solver_summary\n",
    ")\n",
    "from metaforge.utils.visualization import (\n",
    "    plot_gantt_chart,\n",
    "    plot_multiple_gantt,\n",
    "    plot_results_from_csv,\n",
    "    plot_runtime_from_csv\n",
    ")\n",
    "from metaforge.utils.pretty_names import pretty_names\n",
    "from metaforge.metaforge_runner import run_solver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e266f7a",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Load a Benchmark Problem (from URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Mageed-Ghaleb/MetaForge/main/data/benchmarks/ft06.txt\"\n",
    "problem = load_job_shop_instance(url, format=\"orlib\")\n",
    "print(\"âœ… Problem loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e7c62",
   "metadata": {},
   "source": [
    "## ðŸš€ Run All Solvers Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\"sa\", \"ts\", \"ga\", \"aco\", \"q\", \"dqn-naive\", \"dqn-replay\", \"neuroevo\"]\n",
    "results = {}\n",
    "\n",
    "for solver in solvers:\n",
    "    print(f\"ðŸ”§ Running: {solver}\")\n",
    "    result = run_solver(solver, problem, track_schedule=True)\n",
    "    results[solver] = {\n",
    "        \"makespan\": result[\"makespan\"],\n",
    "        \"history\": result.get(\"history\", []),\n",
    "        \"schedules\": result.get(\"schedules\", []),\n",
    "        \"solution\": result.get(\"solution\", [])\n",
    "    }\n",
    "print(\"âœ… All solvers completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef1a0b",
   "metadata": {},
   "source": [
    "## ðŸ“Š Plot Solver Performance (Dashboards + Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard for one solver (e.g., Tabu Search)\n",
    "plot_solver_dashboard(results[\"ts\"][\"history\"], solver_name=\"Tabu Search\")\n",
    "\n",
    "# Compare all convergence curves\n",
    "histories = {pretty_names.get(k, k): v[\"history\"] for k, v in results.items()}\n",
    "plot_convergence_comparison(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defed0d6",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Run Full Comparison Using `compare_solvers()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results = compare_solvers(\n",
    "    solver_names=solvers,\n",
    "    problem=problem,\n",
    "    track_schedule=True,\n",
    "    plot=True  # This calls plot_solver_comparison()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b01609",
   "metadata": {},
   "source": [
    "## ðŸ—‚ Visualize Gantt Chart for a Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30610704",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = problem.get_schedule(results[\"ts\"][\"solution\"])\n",
    "plot_gantt_chart(schedule, num_machines=problem.num_machines, num_jobs=problem.num_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982c3d1",
   "metadata": {},
   "source": [
    "## ðŸ§ª Run Batch Comparison on Multiple Benchmarks (URL-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff967df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_results = compare_all_benchmarks(\n",
    "    benchmark_source=\"https://raw.githubusercontent.com/Mageed-Ghaleb/MetaForge/main/data/benchmarks\",\n",
    "    solvers=solvers,\n",
    "    output_csv=\"results_test.csv\",\n",
    "    track_schedule=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65579aa4",
   "metadata": {},
   "source": [
    "## ðŸ“‰ Plot from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_from_csv(\"results_test.csv\")\n",
    "plot_runtime_from_csv(\"results_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
